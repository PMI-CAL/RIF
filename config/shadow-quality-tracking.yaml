# Shadow Quality Tracking Configuration - Issue #142
# DPIBS Validation Phase 1 Quality Tracking System

quality_tracking:
  name: "Shadow Quality Tracking System"
  version: "1.0.0"
  enabled: true
  
  # Issue #142 specific configuration
  validation_phase: 1
  tracking_period_days: 7  # 5-7 days continuous monitoring
  issue_number: 142
  parent_issue: 129  # DPIBS Validation Phase 1: End-to-End System Integration Testing
  
  # Quality targets from issue requirements
  targets:
    context_relevance_percent: 90.0      # 90% target
    benchmarking_accuracy_percent: 85.0  # 85% target
    agent_improvement_threshold: 75.0     # Measurable improvement threshold
    system_availability_percent: 99.9    # 99.9% availability target
    
  # Performance thresholds
  performance:
    query_response_ms: 200        # Sub-200ms query response consistency
    update_cycle_minutes: 5       # 5-minute update cycle reliability
    availability_monitoring_interval: 30  # 30 second checks
    
  # Adversarial analysis configuration
  adversarial_analysis:
    enabled: true
    continuous_validation: true
    evidence_consolidation: true
    quality_decision_integration: true
    
    # Adversarial validation thresholds
    thresholds:
      critical_finding_escalation: true
      performance_degradation_alert: 10  # 10% degradation triggers alert
      accuracy_drop_alert: 5            # 5% accuracy drop triggers alert
      availability_violation_alert: 0.1  # 0.1% availability drop triggers alert

# Database configuration
database:
  path: "knowledge/quality_tracking.db"
  backup_enabled: true
  backup_interval_hours: 6
  retention_days: 90
  
  # Performance optimization
  connection_pool_size: 5
  query_timeout_seconds: 30
  batch_insert_size: 100

# Monitoring infrastructure
monitoring:
  continuous_monitoring: true
  monitoring_interval_seconds: 30
  
  # Monitoring components
  components:
    system_performance: true
    quality_thresholds: true  
    adversarial_findings: true
    quality_decisions: true
    dashboard_updates: true
    
  # Alerting configuration
  alerts:
    enabled: true
    channels:
      - file_logging
      - github_comments
      - console_output
      
    thresholds:
      context_relevance_below: 85.0     # Alert if below 85%
      benchmarking_accuracy_below: 80.0  # Alert if below 80%
      query_response_above_ms: 250      # Alert if above 250ms
      availability_below: 99.5          # Alert if below 99.5%
      
    escalation:
      critical_immediate: true
      high_within_minutes: 15
      medium_within_hours: 2

# Dashboard configuration  
dashboard:
  enabled: true
  real_time_updates: true
  refresh_interval_seconds: 30
  
  # Dashboard components
  components:
    session_overview: true
    quality_metrics_chart: true
    adversarial_findings_summary: true
    quality_decisions_log: true
    performance_indicators: true
    
  # Export formats
  exports:
    html: true
    json: true
    markdown: true
    
  # Output paths
  paths:
    html_dashboard: "knowledge/quality_monitoring/dashboards/dashboard.html"
    json_data: "knowledge/quality_monitoring/dashboards/current.json"
    markdown_report: "knowledge/quality_monitoring/reports/current.md"

# Evidence consolidation
evidence_consolidation:
  enabled: true
  adversarial_focus: true
  
  # Evidence types to collect
  evidence_types:
    quality_metrics: true
    benchmarking_results: true
    agent_performance_data: true
    system_performance_logs: true
    adversarial_test_results: true
    user_feedback: false  # Not applicable for shadow validation
    
  # Consolidation strategies
  consolidation:
    real_time_aggregation: true
    periodic_summaries: true
    trend_analysis: true
    correlation_detection: true
    
  # Quality scoring
  scoring:
    weighted_average: true
    weights:
      context_relevance: 0.35
      benchmarking_accuracy: 0.35
      system_performance: 0.20
      adversarial_validation: 0.10

# Integration with existing systems
integrations:
  # DPIBS integration
  dpibs_benchmarking:
    enabled: true
    auto_integration: true
    metric_collection: true
    performance_tracking: true
    
  # RIF Shadow Auditor integration
  shadow_auditor:
    enabled: true
    adversarial_findings_import: true
    quality_decision_export: true
    continuous_validation: true
    
  # GitHub integration
  github:
    enabled: true
    auto_comments: true
    progress_updates: true
    final_report_posting: true
    
    comment_triggers:
      quality_threshold_violation: true
      adversarial_finding_critical: true
      session_completion: true
      
  # MCP Knowledge Server integration
  mcp_knowledge:
    enabled: true
    pattern_validation: true
    context_relevance_scoring: true
    knowledge_quality_assessment: true

# Session management
sessions:
  auto_session_creation: true
  session_timeout_hours: 168  # 7 days maximum
  max_concurrent_sessions: 5
  
  # Session lifecycle
  lifecycle:
    auto_start_on_issue_state: "validating"
    auto_end_conditions:
      - issue_closed
      - validation_complete
      - timeout_reached
      - manual_termination
      
    checkpoint_interval_hours: 6
    progress_reporting_interval_hours: 24

# Quality decision framework
quality_decisions:
  enabled: true
  decision_types:
    - validation_approval
    - quality_gate_pass
    - remediation_required
    - escalation_needed
    
  # Decision criteria
  criteria:
    minimum_confidence_score: 0.75
    minimum_evidence_quality: 0.80
    required_metrics:
      - context_relevance
      - benchmarking_accuracy
      
  # Decision automation
  automation:
    auto_approve_threshold: 0.90  # Auto-approve if all metrics > 90% of target
    auto_reject_threshold: 0.70   # Auto-reject if any metric < 70% of target
    manual_review_range: [0.70, 0.90]  # Manual review between thresholds

# Reporting configuration
reporting:
  enabled: true
  
  # Report types
  reports:
    real_time_dashboard: true
    hourly_snapshots: true
    daily_summaries: true
    final_validation_report: true
    
  # Report distribution
  distribution:
    github_issue_comments: true
    file_system_storage: true
    console_output: true
    
  # Report formats
  formats:
    - markdown
    - json
    - html
    
  # Report templates
  templates:
    progress_update: |
      ## ðŸ” Quality Tracking Progress Update
      
      **Session**: {session_id}
      **Issue**: #{issue_number}
      **Duration**: {duration_hours:.1f} hours
      **Status**: {status}
      
      ### Quality Metrics Status
      - **Context Relevance**: {context_relevance:.1f}% (Target: {context_relevance_target}%)
      - **Benchmarking Accuracy**: {benchmarking_accuracy:.1f}% (Target: {benchmarking_accuracy_target}%)
      - **System Performance**: {system_performance:.1f}% (Target: {system_performance_target}%)
      
      ### Adversarial Findings
      - **Total Findings**: {total_findings}
      - **Critical**: {critical_findings}
      - **High**: {high_findings}
      
      **Next Update**: {next_update_time}
      
    final_report: |
      ## ðŸ“Š Shadow Quality Tracking Final Report
      
      **Validation Period**: {start_time} to {end_time}
      **Total Duration**: {total_duration_hours:.1f} hours
      **Issue**: #{issue_number} - {issue_title}
      
      ### Executive Summary
      {executive_summary}
      
      ### Quality Targets Achievement
      - **Context Relevance**: {context_relevance_achievement:.1%} ({'âœ… ACHIEVED' if context_relevance_met else 'âŒ NOT MET'})
      - **Benchmarking Accuracy**: {benchmarking_accuracy_achievement:.1%} ({'âœ… ACHIEVED' if benchmarking_accuracy_met else 'âŒ NOT MET'})
      - **System Performance**: {system_performance_achievement:.1%} ({'âœ… ACHIEVED' if system_performance_met else 'âŒ NOT MET'})
      
      ### Adversarial Analysis Results
      {adversarial_analysis_summary}
      
      ### Quality Decision
      **Recommendation**: {final_recommendation}
      **Confidence**: {confidence_score:.1%}
      **Rationale**: {decision_rationale}
      
      ### Evidence Package
      {evidence_summary}

# Security and privacy
security:
  data_encryption: false  # Internal system, no sensitive data
  access_control: false   # Single-user system
  audit_logging: true
  
  # Data retention
  retention:
    quality_metrics: 365    # Keep metrics for 1 year
    adversarial_findings: 730  # Keep findings for 2 years
    session_data: 180      # Keep session data for 6 months
    
# Performance optimization
performance:
  # Database optimization
  database:
    connection_pooling: true
    query_optimization: true
    index_maintenance: true
    vacuum_interval_days: 7
    
  # Monitoring optimization
  monitoring:
    batch_processing: true
    async_operations: true
    memory_limit_mb: 256
    max_concurrent_operations: 4
    
  # Dashboard optimization
  dashboard:
    data_caching: true
    cache_duration_seconds: 30
    lazy_loading: true
    compression: true

# Development and testing
development:
  debug_mode: false
  verbose_logging: false
  test_data_generation: false
  
  # Testing configuration
  testing:
    mock_metrics: false
    simulated_findings: false
    accelerated_time: false
    test_session_duration_minutes: 30  # For development testing

# Environment-specific overrides
environments:
  development:
    monitoring:
      monitoring_interval_seconds: 10
    dashboard:
      refresh_interval_seconds: 10
    alerts:
      thresholds:
        context_relevance_below: 70.0  # Lower thresholds for dev
        benchmarking_accuracy_below: 65.0
        
  production:
    monitoring:
      monitoring_interval_seconds: 30
    database:
      backup_interval_hours: 2  # More frequent backups
    security:
      audit_logging: true