#!/usr/bin/env python3
"""
Comprehensive Workflow Validation Framework - Issue #89 Complete Implementation
Integrates all validation systems to prevent premature issue closure.

This framework provides:
1. Unified validation interface
2. Integration of all Phase 1 and Phase 2 systems
3. Comprehensive validation reporting  
4. GitHub integration and hooks
5. Validation enforcement and override controls
"""

import json
import subprocess
import yaml
import logging
from datetime import datetime
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path

from github_state_manager import GitHubStateManager
from shadow_quality_tracking import ShadowQualityTracker
from quality_gate_enforcement import QualityGateEnforcement

class ComprehensiveWorkflowValidator:
    """
    Master validation system that orchestrates all workflow validation components.
    """
    
    def __init__(self, config_path: str = "config/rif-workflow.yaml"):
        """Initialize comprehensive validation framework."""
        self.config_path = config_path
        self.config = self._load_config()
        
        # Initialize component systems
        self.state_manager = GitHubStateManager(config_path)
        self.shadow_tracker = ShadowQualityTracker()
        self.quality_enforcer = QualityGateEnforcement(config_path)
        
        self.setup_logging()
        
        # Validation configuration
        self.validation_config = self.config.get('workflow', {}).get('closure_validation', {
            'enabled': True,
            'required_validations': [
                'state_completion_check',
                'quality_gate_validation',
                'evidence_requirements_check',
                'shadow_issue_closure_check'
            ],
            'blocking_policy': 'hard_block',
            'authorized_overrides': {
                'enabled': True,
                'audit_required': True
            }
        })
        
    def setup_logging(self):
        """Setup logging for comprehensive validation."""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - ComprehensiveValidator - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def _load_config(self) -> Dict[str, Any]:
        """Load workflow configuration."""
        try:
            config_file = Path(self.config_path)
            if config_file.exists():
                with open(config_file, 'r') as f:
                    return yaml.safe_load(f)
            else:
                self.logger.warning(f"Config file {self.config_path} not found")
                return {}
        except Exception as e:
            self.logger.error(f"Error loading config: {e}")
            return {}
    
    def validate_issue_for_closure(self, issue_number: int, override_user: Optional[str] = None, override_reason: Optional[str] = None) -> Dict[str, Any]:
        """
        Comprehensive validation of issue closure readiness.
        
        Args:
            issue_number: GitHub issue number
            override_user: User requesting override (if any)
            override_reason: Reason for override (if any)
            
        Returns:
            Complete validation report with closure decision
        """
        self.logger.info(f"ðŸ” Starting comprehensive closure validation for issue #{issue_number}")
        
        comprehensive_report = {
            'issue_number': issue_number,
            'validation_timestamp': datetime.now().isoformat(),
            'can_close': True,
            'validation_results': {},
            'overall_status': 'pending',
            'blocking_reasons': [],
            'warnings': [],
            'override_request': None,
            'final_decision': None,
            'audit_trail': []
        }
        
        # Handle override requests
        if override_user and override_reason:
            comprehensive_report['override_request'] = {
                'user': override_user,
                'reason': override_reason,
                'timestamp': datetime.now().isoformat()
            }
        
        try:
            # 1. State Completion Check
            self.logger.info("Running state completion validation...")
            state_validation = self._validate_state_completion(issue_number)
            comprehensive_report['validation_results']['state_completion'] = state_validation
            self._update_overall_status(comprehensive_report, state_validation, 'State completion check')
            
            # 2. Quality Gate Validation
            self.logger.info("Running quality gate validation...")
            quality_validation = self.quality_enforcer.validate_issue_closure_readiness(issue_number)
            comprehensive_report['validation_results']['quality_gates'] = quality_validation
            self._update_overall_status(comprehensive_report, quality_validation, 'Quality gate validation')
            
            # 3. Evidence Requirements Check
            self.logger.info("Running evidence requirements validation...")
            evidence_validation = self._validate_evidence_completeness(issue_number)
            comprehensive_report['validation_results']['evidence_requirements'] = evidence_validation
            self._update_overall_status(comprehensive_report, evidence_validation, 'Evidence requirements check')
            
            # 4. Shadow Issue Closure Check
            self.logger.info("Running shadow issue validation...")
            shadow_validation = self._validate_shadow_issue_closure(issue_number)
            comprehensive_report['validation_results']['shadow_issue'] = shadow_validation
            self._update_overall_status(comprehensive_report, shadow_validation, 'Shadow issue check')
            
            # 5. Integration Validation
            self.logger.info("Running integration validation...")
            integration_validation = self._validate_system_integration(issue_number)
            comprehensive_report['validation_results']['integration'] = integration_validation
            self._update_overall_status(comprehensive_report, integration_validation, 'System integration check')
            
            # 6. Final Decision Logic
            comprehensive_report['final_decision'] = self._make_final_closure_decision(comprehensive_report)
            
            # 7. Audit Trail
            comprehensive_report['audit_trail'] = self._generate_audit_trail(comprehensive_report, issue_number)
            
            # Log final result
            if comprehensive_report['final_decision']['can_close']:
                self.logger.info(f"âœ… Issue #{issue_number} validated for closure")
            else:
                self.logger.warning(f"âŒ Issue #{issue_number} blocked from closure: {len(comprehensive_report['blocking_reasons'])} blocking reasons")
            
            return comprehensive_report
            
        except Exception as e:
            self.logger.error(f"Error in comprehensive validation: {e}")
            comprehensive_report['can_close'] = False
            comprehensive_report['overall_status'] = 'error'
            comprehensive_report['blocking_reasons'].append(f"Validation system error: {e}")
            comprehensive_report['final_decision'] = {
                'can_close': False,
                'decision_reason': 'Validation system error',
                'requires_manual_review': True
            }
            return comprehensive_report
    
    def _validate_state_completion(self, issue_number: int) -> Dict[str, Any]:
        """Validate that the issue workflow state is complete."""
        validation_result = {
            'passed': False,
            'current_state': None,
            'valid_final_states': ['complete', 'failed'],
            'state_transitions': [],
            'recommendations': []
        }
        
        try:
            # Get current state
            current_state = self.state_manager.get_current_state(issue_number)
            validation_result['current_state'] = current_state
            
            # Validate state
            if current_state in validation_result['valid_final_states']:
                validation_result['passed'] = True
                validation_result['message'] = f"Issue in valid final state: {current_state}"
            else:
                validation_result['passed'] = False
                validation_result['message'] = f"Issue in state '{current_state}', expected one of {validation_result['valid_final_states']}"
                validation_result['recommendations'].append(f"Transition issue to 'complete' or 'failed' state before closure")
            
            # Get state transition history
            validation_result['state_transitions'] = self._get_state_transition_history(issue_number)
            
            return validation_result
            
        except Exception as e:
            validation_result['passed'] = False
            validation_result['error'] = str(e)
            validation_result['message'] = f"State validation error: {e}"
            return validation_result
    
    def _validate_evidence_completeness(self, issue_number: int) -> Dict[str, Any]:
        """Validate evidence completeness beyond basic quality gates."""
        validation_result = {
            'passed': True,
            'evidence_score': 0,
            'missing_critical_evidence': [],
            'quality_evidence_present': [],
            'recommendations': []
        }
        
        try:
            # Get issue details for evidence analysis
            issue_details = self._get_issue_details(issue_number)
            if not issue_details:
                validation_result['passed'] = False
                validation_result['error'] = "Could not retrieve issue details"
                return validation_result
            
            # Check for implementation evidence
            implementation_evidence = self._check_implementation_evidence(issue_number)
            validation_result.update(implementation_evidence)
            
            # Check for validation evidence
            validation_evidence = self._check_validation_evidence(issue_number)
            if validation_evidence['validation_evidence_count'] < 2:
                validation_result['passed'] = False
                validation_result['missing_critical_evidence'].append("Insufficient validation evidence (need at least 2 validation activities)")
            
            # Check for completion evidence
            completion_evidence = self._check_completion_evidence(issue_number, issue_details)
            validation_result.update(completion_evidence)
            
            # Calculate evidence score
            evidence_score = (
                (len(validation_result['quality_evidence_present']) * 20) +
                (validation_evidence['validation_evidence_count'] * 15) +
                (50 if completion_evidence.get('has_completion_evidence', False) else 0)
            )
            validation_result['evidence_score'] = min(100, evidence_score)
            
            if validation_result['evidence_score'] < 80:
                validation_result['passed'] = False
                validation_result['missing_critical_evidence'].append(f"Evidence score {validation_result['evidence_score']} below threshold 80")
            
            return validation_result
            
        except Exception as e:
            validation_result['passed'] = False
            validation_result['error'] = str(e)
            return validation_result
    
    def _validate_shadow_issue_closure(self, issue_number: int) -> Dict[str, Any]:
        """Validate shadow issue closure requirements."""
        validation_result = {
            'passed': True,
            'shadow_required': False,
            'shadow_exists': False,
            'shadow_ready_for_closure': False,
            'shadow_issue_number': None,
            'recommendations': []
        }
        
        try:
            # Check if issue should have shadow
            should_have_shadow = self._should_have_shadow_issue(issue_number)
            validation_result['shadow_required'] = should_have_shadow
            
            if not should_have_shadow:
                validation_result['message'] = "No shadow issue required for this issue"
                return validation_result
            
            # Check if shadow exists
            shadow_number = self._find_shadow_issue(issue_number)
            validation_result['shadow_exists'] = shadow_number is not None
            validation_result['shadow_issue_number'] = shadow_number
            
            if not shadow_number:
                validation_result['passed'] = False
                validation_result['message'] = "Shadow issue required but not found"
                validation_result['recommendations'].append("Create shadow quality tracking issue before closure")
                return validation_result
            
            # Check shadow closure readiness
            shadow_ready = self._check_shadow_closure_readiness(shadow_number)
            validation_result['shadow_ready_for_closure'] = shadow_ready['ready']
            
            if not shadow_ready['ready']:
                validation_result['passed'] = False
                validation_result['message'] = f"Shadow issue #{shadow_number} not ready for closure"
                validation_result['recommendations'].extend(shadow_ready.get('requirements', []))
            else:
                validation_result['message'] = f"Shadow issue #{shadow_number} ready for closure"
            
            return validation_result
            
        except Exception as e:
            validation_result['passed'] = False
            validation_result['error'] = str(e)
            return validation_result
    
    def _validate_system_integration(self, issue_number: int) -> Dict[str, Any]:
        """Validate system integration and consistency."""
        validation_result = {
            'passed': True,
            'system_consistency': True,
            'integration_checks': [],
            'warnings': []
        }
        
        try:
            # Check state manager consistency
            state_audit = self.state_manager.validate_issue_state(issue_number)
            integration_check = {
                'system': 'state_manager',
                'passed': state_audit['is_valid'],
                'details': state_audit
            }
            validation_result['integration_checks'].append(integration_check)
            
            if not state_audit['is_valid']:
                validation_result['passed'] = False
                validation_result['system_consistency'] = False
            
            # Check for GitHub API consistency
            github_check = self._validate_github_consistency(issue_number)
            validation_result['integration_checks'].append(github_check)
            
            if not github_check['passed']:
                validation_result['warnings'].append("GitHub API consistency issues detected")
            
            return validation_result
            
        except Exception as e:
            validation_result['passed'] = False
            validation_result['error'] = str(e)
            return validation_result
    
    def _make_final_closure_decision(self, comprehensive_report: Dict[str, Any]) -> Dict[str, Any]:
        """Make final decision about issue closure based on all validation results."""
        decision = {
            'can_close': comprehensive_report['can_close'],
            'decision_reason': '',
            'override_applied': False,
            'requires_manual_review': False,
            'next_steps': []
        }
        
        # Check override request
        override_request = comprehensive_report.get('override_request')
        if override_request and self.validation_config.get('authorized_overrides', {}).get('enabled', False):
            if self._validate_override_authorization(override_request):
                decision['can_close'] = True
                decision['override_applied'] = True
                decision['decision_reason'] = f"Override approved: {override_request['reason']}"
                decision['next_steps'].append("Manual review required due to override")
            else:
                decision['requires_manual_review'] = True
                decision['decision_reason'] = "Override requested but not authorized"
        
        # Standard decision logic
        if not decision['override_applied']:
            if comprehensive_report['can_close']:
                decision['decision_reason'] = "All validation checks passed"
                decision['next_steps'].append("Issue can be safely closed")
            else:
                blocking_count = len(comprehensive_report['blocking_reasons'])
                decision['decision_reason'] = f"Validation failed: {blocking_count} blocking reasons"
                decision['next_steps'].extend([
                    "Address all blocking reasons before attempting closure",
                    "Re-run validation after fixes are applied"
                ])
                
                # Check if manual review might help
                if blocking_count <= 2 and len(comprehensive_report['warnings']) == 0:
                    decision['next_steps'].append("Consider manual review if blocking reasons are minor")
        
        return decision
    
    def enforce_closure_validation(self, issue_number: int, action: str = "close") -> Dict[str, Any]:
        """
        Enforce closure validation when an issue is being closed.
        This is the main enforcement entry point.
        
        Args:
            issue_number: GitHub issue number
            action: Action being performed ('close', 'validate', 'preview')
            
        Returns:
            Enforcement result with action taken
        """
        self.logger.info(f"ðŸ›¡ï¸ Enforcing closure validation for issue #{issue_number} (action: {action})")
        
        enforcement_result = {
            'issue_number': issue_number,
            'action_requested': action,
            'action_allowed': False,
            'enforcement_timestamp': datetime.now().isoformat(),
            'validation_report': None,
            'action_taken': 'blocked',
            'message': '',
            'next_steps': []
        }
        
        try:
            # Run comprehensive validation
            validation_report = self.validate_issue_for_closure(issue_number)
            enforcement_result['validation_report'] = validation_report
            
            # Make enforcement decision
            if validation_report['final_decision']['can_close']:
                enforcement_result['action_allowed'] = True
                enforcement_result['action_taken'] = 'allowed'
                enforcement_result['message'] = "Issue closure validated and allowed"
                
                if action == "close":
                    # Perform any pre-closure actions
                    self._perform_pre_closure_actions(issue_number, validation_report)
                    enforcement_result['action_taken'] = 'executed'
                    enforcement_result['message'] = "Issue closure validated and executed"
                
            else:
                enforcement_result['action_allowed'] = False
                enforcement_result['action_taken'] = 'blocked'
                enforcement_result['message'] = f"Issue closure blocked: {validation_report['final_decision']['decision_reason']}"
                enforcement_result['next_steps'] = validation_report['final_decision']['next_steps']
                
                # Post blocking comment to GitHub
                if action == "close":
                    self._post_closure_blocked_comment(issue_number, validation_report)
            
            return enforcement_result
            
        except Exception as e:
            self.logger.error(f"Error in closure enforcement: {e}")
            enforcement_result['action_allowed'] = False
            enforcement_result['action_taken'] = 'error'
            enforcement_result['message'] = f"Enforcement system error: {e}"
            return enforcement_result
    
    def generate_system_status_report(self) -> Dict[str, Any]:
        """Generate comprehensive system status report."""
        self.logger.info("ðŸ“Š Generating comprehensive system status report...")
        
        status_report = {
            'report_timestamp': datetime.now().isoformat(),
            'system_health': {},
            'validation_statistics': {},
            'issue_compliance': {},
            'recommendations': []
        }
        
        try:
            # System health checks
            status_report['system_health'] = {
                'state_manager': self._check_system_health('state_manager'),
                'quality_gates': self._check_system_health('quality_gates'),
                'shadow_tracker': self._check_system_health('shadow_tracker'),
                'validation_framework': self._check_system_health('validation_framework')
            }
            
            # Overall statistics
            open_issues = self.state_manager.get_all_open_issues()
            status_report['validation_statistics'] = {
                'total_open_issues': len(open_issues),
                'issues_ready_for_closure': 0,
                'issues_blocked_from_closure': 0,
                'average_quality_score': 0,
                'shadow_issues_active': 0
            }
            
            # Issue compliance analysis
            compliance_results = []
            for issue_number in open_issues[:10]:  # Sample first 10 for performance
                validation = self.validate_issue_for_closure(issue_number)
                compliance_results.append({
                    'issue': issue_number,
                    'can_close': validation['final_decision']['can_close'],
                    'quality_score': validation['validation_results'].get('quality_gates', {}).get('quality_score', {}).get('score', 0)
                })
            
            # Calculate statistics
            ready_count = sum(1 for r in compliance_results if r['can_close'])
            blocked_count = len(compliance_results) - ready_count
            avg_score = sum(r['quality_score'] for r in compliance_results) / len(compliance_results) if compliance_results else 0
            
            status_report['validation_statistics'].update({
                'issues_ready_for_closure': ready_count,
                'issues_blocked_from_closure': blocked_count,
                'average_quality_score': round(avg_score, 1)
            })
            
            # Generate recommendations
            status_report['recommendations'] = self._generate_system_recommendations(status_report)
            
            return status_report
            
        except Exception as e:
            self.logger.error(f"Error generating status report: {e}")
            status_report['error'] = str(e)
            return status_report
    
    # Helper methods (private)
    
    def _update_overall_status(self, report: Dict[str, Any], validation_result: Dict[str, Any], validation_name: str):
        """Update overall status based on individual validation results."""
        if not validation_result.get('can_close', validation_result.get('passed', True)):
            report['can_close'] = False
            
            # Add blocking reasons
            if 'blocking_reasons' in validation_result:
                report['blocking_reasons'].extend(validation_result['blocking_reasons'])
            elif validation_result.get('message'):
                report['blocking_reasons'].append(f"{validation_name}: {validation_result['message']}")
        
        # Add warnings
        if 'warnings' in validation_result:
            report['warnings'].extend(validation_result['warnings'])
    
    def _get_state_transition_history(self, issue_number: int) -> List[Dict[str, Any]]:
        """Get state transition history for the issue."""
        try:
            log_file = Path('knowledge/state_transitions/transitions.jsonl')
            if not log_file.exists():
                return []
            
            transitions = []
            with open(log_file, 'r') as f:
                for line in f:
                    try:
                        entry = json.loads(line.strip())
                        if entry.get('issue_number') == issue_number:
                            transitions.append(entry)
                    except json.JSONDecodeError:
                        continue
            
            return sorted(transitions, key=lambda x: x.get('timestamp', ''))
            
        except Exception as e:
            self.logger.warning(f"Error getting transition history: {e}")
            return []
    
    def _get_issue_details(self, issue_number: int) -> Optional[Dict[str, Any]]:
        """Get comprehensive issue details."""
        return self.quality_enforcer._get_issue_details(issue_number)
    
    def _check_implementation_evidence(self, issue_number: int) -> Dict[str, Any]:
        """Check for evidence of actual implementation work."""
        evidence_result = {
            'has_implementation_evidence': False,
            'quality_evidence_present': []
        }
        
        try:
            result = subprocess.run([
                'gh', 'issue', 'view', str(issue_number),
                '--json', 'comments'
            ], capture_output=True, text=True, check=True)
            
            issue_data = json.loads(result.stdout)
            comments = issue_data.get('comments', [])
            
            implementation_keywords = ['implemented', 'coded', 'developed', 'built', 'created', 'fixed', 'resolved']
            quality_keywords = ['tested', 'verified', 'validated', 'reviewed', 'approved']
            
            for comment in comments:
                body = comment.get('body', '').lower()
                
                if any(keyword in body for keyword in implementation_keywords):
                    evidence_result['has_implementation_evidence'] = True
                
                for keyword in quality_keywords:
                    if keyword in body and keyword not in evidence_result['quality_evidence_present']:
                        evidence_result['quality_evidence_present'].append(keyword)
            
            return evidence_result
            
        except Exception as e:
            evidence_result['error'] = str(e)
            return evidence_result
    
    def _check_validation_evidence(self, issue_number: int) -> Dict[str, Any]:
        """Check for validation and testing evidence."""
        validation_result = {
            'validation_evidence_count': 0,
            'validation_activities': []
        }
        
        try:
            result = subprocess.run([
                'gh', 'issue', 'view', str(issue_number),
                '--json', 'comments'
            ], capture_output=True, text=True, check=True)
            
            issue_data = json.loads(result.stdout)
            comments = issue_data.get('comments', [])
            
            validation_keywords = ['test', 'validate', 'verify', 'check', 'confirm', 'prove']
            
            for comment in comments:
                body = comment.get('body', '').lower()
                for keyword in validation_keywords:
                    if keyword in body:
                        validation_result['validation_evidence_count'] += 1
                        validation_result['validation_activities'].append({
                            'keyword': keyword,
                            'comment_excerpt': body[:100] + '...' if len(body) > 100 else body
                        })
                        break  # Count each comment only once
            
            return validation_result
            
        except Exception as e:
            validation_result['error'] = str(e)
            return validation_result
    
    def _check_completion_evidence(self, issue_number: int, issue_details: Dict[str, Any]) -> Dict[str, Any]:
        """Check for completion evidence."""
        completion_result = {
            'has_completion_evidence': False,
            'completion_indicators': []
        }
        
        try:
            # Check comments for completion evidence
            result = subprocess.run([
                'gh', 'issue', 'view', str(issue_number),
                '--json', 'comments'
            ], capture_output=True, text=True, check=True)
            
            issue_data = json.loads(result.stdout)
            comments = issue_data.get('comments', [])
            
            completion_keywords = ['complete', 'finished', 'done', 'ready', 'final']
            
            for comment in comments:
                body = comment.get('body', '').lower()
                for keyword in completion_keywords:
                    if keyword in body:
                        completion_result['has_completion_evidence'] = True
                        completion_result['completion_indicators'].append(keyword)
                        break
            
            return completion_result
            
        except Exception as e:
            completion_result['error'] = str(e)
            return completion_result
    
    def _should_have_shadow_issue(self, issue_number: int) -> bool:
        """Check if issue should have shadow issue (delegate to workflow validation system)."""
        try:
            from workflow_validation_system import WorkflowValidationSystem
            validator = WorkflowValidationSystem()
            return validator._should_have_shadow_issue(issue_number)
        except Exception as e:
            self.logger.warning(f"Error checking shadow requirements: {e}")
            return False
    
    def _find_shadow_issue(self, issue_number: int) -> Optional[int]:
        """Find shadow issue for main issue."""
        try:
            result = subprocess.run([
                'gh', 'issue', 'list', '--state', 'all',
                '--search', f'"Quality Tracking: Issue #{issue_number}"',
                '--json', 'number'
            ], capture_output=True, text=True, check=True)
            
            issues = json.loads(result.stdout)
            return issues[0]['number'] if issues else None
            
        except Exception:
            return None
    
    def _check_shadow_closure_readiness(self, shadow_number: int) -> Dict[str, Any]:
        """Check if shadow issue is ready for closure."""
        readiness_result = {
            'ready': False,
            'requirements': []
        }
        
        try:
            # Check shadow issue state
            shadow_state = self.state_manager.get_current_state(shadow_number)
            if shadow_state not in ['complete', 'validating']:
                readiness_result['requirements'].append(f"Shadow issue in state '{shadow_state}', should be 'complete' or 'validating'")
            else:
                readiness_result['ready'] = True
            
            return readiness_result
            
        except Exception as e:
            readiness_result['error'] = str(e)
            return readiness_result
    
    def _validate_github_consistency(self, issue_number: int) -> Dict[str, Any]:
        """Validate GitHub API consistency."""
        return {
            'system': 'github_api',
            'passed': True,  # Placeholder - would implement actual GitHub consistency checks
            'details': {
                'api_responsive': True,
                'data_consistent': True
            }
        }
    
    def _validate_override_authorization(self, override_request: Dict[str, Any]) -> bool:
        """Validate if user is authorized for override."""
        # In a real implementation, this would check user permissions
        authorized_users = ['PMI-CAL', 'admin', 'maintainer']  # Example authorized users
        return override_request.get('user') in authorized_users
    
    def _perform_pre_closure_actions(self, issue_number: int, validation_report: Dict[str, Any]):
        """Perform pre-closure actions like updating shadow issues."""
        try:
            # Close associated shadow issue if it exists
            shadow_validation = validation_report['validation_results'].get('shadow_issue', {})
            if shadow_validation.get('shadow_issue_number'):
                shadow_number = shadow_validation['shadow_issue_number']
                self.logger.info(f"Closing associated shadow issue #{shadow_number}")
                # Would implement shadow issue closure here
            
        except Exception as e:
            self.logger.warning(f"Error in pre-closure actions: {e}")
    
    def _post_closure_blocked_comment(self, issue_number: int, validation_report: Dict[str, Any]):
        """Post comment explaining why closure was blocked."""
        try:
            blocking_reasons = validation_report.get('blocking_reasons', [])
            recommendations = validation_report['final_decision'].get('next_steps', [])
            
            comment = f"""## ðŸ”’ Issue Closure Blocked
            
This issue cannot be closed because it does not meet the required validation criteria.

### Blocking Reasons:
{chr(10).join([f'â€¢ {reason}' for reason in blocking_reasons])}

### Required Actions:
{chr(10).join([f'â€¢ {rec}' for rec in recommendations])}

### Quality Score:
Current score: {validation_report['validation_results'].get('quality_gates', {}).get('quality_score', {}).get('score', 'N/A')}

Re-run validation after addressing the blocking reasons: `python validate_issue_closure.py {issue_number}`

*This is an automated message from the RIF Workflow Validation System.*"""
            
            self.state_manager.post_comment_to_issue(issue_number, comment)
            
        except Exception as e:
            self.logger.warning(f"Error posting blocked comment: {e}")
    
    def _check_system_health(self, system_name: str) -> Dict[str, Any]:
        """Check health of individual system components."""
        health_result = {
            'status': 'healthy',
            'last_check': datetime.now().isoformat(),
            'issues': []
        }
        
        try:
            if system_name == 'state_manager':
                # Check if state manager is working
                test_audit = self.state_manager.audit_all_issues()
                if test_audit.get('error'):
                    health_result['status'] = 'error'
                    health_result['issues'].append('State manager audit failed')
                    
            elif system_name == 'quality_gates':
                # Check if quality gates are configured
                if not self.quality_enforcer.quality_gates:
                    health_result['status'] = 'warning'
                    health_result['issues'].append('No quality gates configured')
                    
            elif system_name == 'shadow_tracker':
                # Check if shadow tracker is functional
                # Placeholder for actual health check
                pass
                
            elif system_name == 'validation_framework':
                # Check if validation framework is working
                if not self.validation_config.get('enabled', True):
                    health_result['status'] = 'disabled'
                    health_result['issues'].append('Validation framework disabled')
            
            return health_result
            
        except Exception as e:
            health_result['status'] = 'error'
            health_result['issues'].append(f'Health check error: {e}')
            return health_result
    
    def _generate_system_recommendations(self, status_report: Dict[str, Any]) -> List[str]:
        """Generate system improvement recommendations."""
        recommendations = []
        
        # Check system health
        health = status_report.get('system_health', {})
        for system, health_info in health.items():
            if health_info['status'] == 'error':
                recommendations.append(f"ðŸ”´ Fix {system} system: {', '.join(health_info['issues'])}")
            elif health_info['status'] == 'warning':
                recommendations.append(f"ðŸŸ¡ Review {system} configuration: {', '.join(health_info['issues'])}")
        
        # Check validation statistics
        stats = status_report.get('validation_statistics', {})
        if stats.get('average_quality_score', 0) < 80:
            recommendations.append(f"ðŸ“Š Average quality score ({stats.get('average_quality_score', 0)}) is below target (80)")
        
        blocked_percentage = (stats.get('issues_blocked_from_closure', 0) / max(1, stats.get('total_open_issues', 1))) * 100
        if blocked_percentage > 50:
            recommendations.append(f"âš ï¸ {blocked_percentage:.1f}% of issues blocked from closure - review validation criteria")
        
        # If no issues found
        if not recommendations:
            recommendations.append("âœ… All systems healthy - no action required")
        
        return recommendations
    
    def _generate_audit_trail(self, comprehensive_report: Dict[str, Any], issue_number: int) -> List[Dict[str, Any]]:
        """Generate audit trail for validation process."""
        audit_trail = []
        
        try:
            # Add validation timestamp
            audit_trail.append({
                'timestamp': comprehensive_report['validation_timestamp'],
                'action': 'validation_started',
                'details': f"Comprehensive validation started for issue #{issue_number}"
            })
            
            # Add validation results
            for validation_type, result in comprehensive_report.get('validation_results', {}).items():
                audit_trail.append({
                    'timestamp': datetime.now().isoformat(),
                    'action': f'{validation_type}_validation',
                    'passed': result.get('passed', result.get('can_close', True)),
                    'details': result.get('message', f'{validation_type} validation completed')
                })
            
            # Add final decision
            if comprehensive_report.get('final_decision'):
                audit_trail.append({
                    'timestamp': datetime.now().isoformat(),
                    'action': 'final_decision',
                    'decision': comprehensive_report['final_decision']['can_close'],
                    'reason': comprehensive_report['final_decision']['decision_reason']
                })
            
            return audit_trail
            
        except Exception as e:
            return [{
                'timestamp': datetime.now().isoformat(),
                'action': 'audit_trail_error',
                'error': str(e)
            }]


def main():
    """Command line interface for comprehensive workflow validator."""
    import sys
    
    if len(sys.argv) < 2:
        print("Usage: python comprehensive_workflow_validator.py <command> [args]")
        print("Commands:")
        print("  validate-closure <issue_number>       - Full closure validation")
        print("  enforce-closure <issue_number>        - Enforce closure validation")
        print("  system-status                         - Generate system status report")
        print("  validate-batch <start> <end>          - Validate batch of issues")
        return
    
    command = sys.argv[1]
    validator = ComprehensiveWorkflowValidator()
    
    if command == "validate-closure" and len(sys.argv) >= 3:
        issue_num = int(sys.argv[2])
        result = validator.validate_issue_for_closure(issue_num)
        print(json.dumps(result, indent=2))
        
        if not result['final_decision']['can_close']:
            return 1
        
    elif command == "enforce-closure" and len(sys.argv) >= 3:
        issue_num = int(sys.argv[2])
        result = validator.enforce_closure_validation(issue_num, "close")
        print(json.dumps(result, indent=2))
        
        if not result['action_allowed']:
            return 1
        
    elif command == "system-status":
        result = validator.generate_system_status_report()
        print(json.dumps(result, indent=2))
        
    elif command == "validate-batch" and len(sys.argv) >= 4:
        start_issue = int(sys.argv[2])
        end_issue = int(sys.argv[3])
        
        results = []
        for issue_num in range(start_issue, end_issue + 1):
            try:
                result = validator.validate_issue_for_closure(issue_num)
                results.append({
                    'issue': issue_num,
                    'can_close': result['final_decision']['can_close'],
                    'quality_score': result['validation_results'].get('quality_gates', {}).get('quality_score', {}).get('score', 0)
                })
            except Exception as e:
                results.append({
                    'issue': issue_num,
                    'error': str(e)
                })
        
        print(json.dumps({'batch_results': results}, indent=2))
        
    else:
        print(f"Unknown command: {command}")
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())