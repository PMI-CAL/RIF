#!/usr/bin/env python3
"""
Agent Context Delivery Enhancement Implementation
Issue #135: Agent Context Delivery Research Implementation

Based on research findings for DPIBS Research Phase 3, this module enhances
the existing context delivery system with:

1. Integration with existing Agent-Aware Context Optimization Pattern
2. System context injection mechanisms for agent overview information
3. Information overload prevention with intelligent context pruning
4. Sub-50ms optimization latency maintenance

Research Foundation: 90% existing infrastructure, 10% integration needed
Building on proven Agent-Aware Context Optimization Pattern
"""

import json
import os
import time
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Set, Tuple, Union
from dataclasses import dataclass, asdict
from enum import Enum
from pathlib import Path
import hashlib
import asyncio

# Import existing infrastructure
import sys
sys.path.append('/Users/cal/DEV/RIF/systems')

class AgentType(Enum):
    """RIF Agent types with specific context requirements"""
    RIF_ANALYST = "rif_analyst"
    RIF_ARCHITECT = "rif_architect"
    RIF_IMPLEMENTER = "rif_implementer"
    RIF_VALIDATOR = "rif_validator"
    RIF_LEARNER = "rif_learner"
    RIF_PLANNER = "rif_planner"
    RIF_PR_MANAGER = "rif_pr_manager"
    RIF_ERROR_ANALYST = "rif_error_analyst"
    RIF_SHADOW_AUDITOR = "rif_shadow_auditor"
    RIF_PROJECTGEN = "rif_projectgen"

class ContextType(Enum):
    """Types of context information"""
    SYSTEM_OVERVIEW = "system_overview"
    ARCHITECTURAL_DESIGN = "architectural_design"
    DEPENDENCY_GRAPH = "dependency_graph"
    WORKFLOW_STATE = "workflow_state"
    QUALITY_METRICS = "quality_metrics"
    RECENT_CHANGES = "recent_changes"
    KNOWLEDGE_PATTERNS = "knowledge_patterns"
    PERFORMANCE_DATA = "performance_data"

class RelevanceLevel(Enum):
    """Context relevance levels for filtering"""
    CRITICAL = "critical"  # Must include
    HIGH = "high"  # Should include
    MEDIUM = "medium"  # Include if space permits
    LOW = "low"  # Include only if plenty of space
    IRRELEVANT = "irrelevant"  # Never include

@dataclass
class AgentContextConfiguration:
    """Configuration for agent-specific context delivery"""
    agent_type: AgentType
    token_limit: int
    context_priorities: Dict[ContextType, RelevanceLevel]
    focus_areas: List[str]
    optimization_targets: Dict[str, Any]
    performance_requirements: Dict[str, float]
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['agent_type'] = self.agent_type.value
        data['context_priorities'] = {
            k.value: v.value for k, v in self.context_priorities.items()
        }
        return data

@dataclass
class SystemContextItem:
    """Individual system context item with relevance scoring"""
    context_type: ContextType
    content: Dict[str, Any]
    relevance_score: float  # 0.0 to 1.0
    token_estimate: int
    freshness_score: float  # 0.0 to 1.0 (how recent/current)
    accuracy_score: float  # 0.0 to 1.0 (validation confidence)
    source_component: str
    last_updated: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['context_type'] = self.context_type.value
        data['last_updated'] = self.last_updated.isoformat()
        return data

@dataclass
class OptimizedContextDelivery:
    """Optimized context delivery result for specific agent"""
    agent_type: AgentType
    context_items: List[SystemContextItem]
    total_tokens: int
    optimization_duration_ms: float
    relevance_filtering_applied: bool
    information_overload_prevented: bool
    context_freshness_score: float
    delivery_timestamp: datetime
    
    def to_dict(self) -> Dict[str, Any]:
        data = asdict(self)
        data['agent_type'] = self.agent_type.value
        data['context_items'] = [item.to_dict() for item in self.context_items]
        data['delivery_timestamp'] = self.delivery_timestamp.isoformat()
        return data

class AgentContextConfigurator:
    """Manages agent-specific context configurations based on research findings"""
    
    def __init__(self):
        self.agent_configurations = self._initialize_agent_configurations()
        self.multi_factor_weights = {
            'text': 0.40,  # Direct text relevance
            'semantic': 0.30,  # Semantic similarity
            'structural': 0.20,  # Structural importance
            'temporal': 0.10  # Temporal relevance
        }
    
    def _initialize_agent_configurations(self) -> Dict[AgentType, AgentContextConfiguration]:
        """Initialize agent configurations based on research findings"""
        return {
            AgentType.RIF_ANALYST: AgentContextConfiguration(
                agent_type=AgentType.RIF_ANALYST,
                token_limit=8000,
                context_priorities={
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.CRITICAL,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.HIGH,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.HIGH,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.HIGH,
                    ContextType.RECENT_CHANGES: RelevanceLevel.MEDIUM,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.MEDIUM,
                    ContextType.QUALITY_METRICS: RelevanceLevel.MEDIUM,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.LOW
                },
                focus_areas=["requirements_analysis", "pattern_recognition", "complexity_assessment"],
                optimization_targets={"analysis_depth": "comprehensive", "pattern_matching": "extensive"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.9}
            ),
            
            AgentType.RIF_ARCHITECT: AgentContextConfiguration(
                agent_type=AgentType.RIF_ARCHITECT,
                token_limit=12000,
                context_priorities={
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.CRITICAL,
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.CRITICAL,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.CRITICAL,
                    ContextType.QUALITY_METRICS: RelevanceLevel.HIGH,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.HIGH,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.HIGH,
                    ContextType.RECENT_CHANGES: RelevanceLevel.MEDIUM,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.LOW
                },
                focus_areas=["system_design", "architectural_patterns", "scalability", "integration"],
                optimization_targets={"design_comprehensiveness": "maximal", "pattern_application": "extensive"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.95}
            ),
            
            AgentType.RIF_IMPLEMENTER: AgentContextConfiguration(
                agent_type=AgentType.RIF_IMPLEMENTER,
                token_limit=6000,
                context_priorities={
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.HIGH,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.CRITICAL,
                    ContextType.RECENT_CHANGES: RelevanceLevel.CRITICAL,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.HIGH,
                    ContextType.QUALITY_METRICS: RelevanceLevel.HIGH,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.MEDIUM,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.MEDIUM,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.LOW
                },
                focus_areas=["implementation", "code_quality", "testing", "integration"],
                optimization_targets={"implementation_focus": "actionable", "context_precision": "high"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.85}
            ),
            
            AgentType.RIF_VALIDATOR: AgentContextConfiguration(
                agent_type=AgentType.RIF_VALIDATOR,
                token_limit=8000,
                context_priorities={
                    ContextType.QUALITY_METRICS: RelevanceLevel.CRITICAL,
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.HIGH,
                    ContextType.RECENT_CHANGES: RelevanceLevel.CRITICAL,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.HIGH,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.HIGH,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.MEDIUM,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.MEDIUM,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.LOW
                },
                focus_areas=["quality_assurance", "testing", "validation", "compliance"],
                optimization_targets={"validation_thoroughness": "comprehensive", "quality_focus": "maximal"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.9}
            ),
            
            AgentType.RIF_LEARNER: AgentContextConfiguration(
                agent_type=AgentType.RIF_LEARNER,
                token_limit=10000,
                context_priorities={
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.CRITICAL,
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.HIGH,
                    ContextType.RECENT_CHANGES: RelevanceLevel.HIGH,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.HIGH,
                    ContextType.QUALITY_METRICS: RelevanceLevel.HIGH,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.MEDIUM,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.MEDIUM,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.LOW
                },
                focus_areas=["learning", "patterns", "optimization", "knowledge_synthesis"],
                optimization_targets={"learning_comprehensiveness": "extensive", "pattern_extraction": "maximal"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.85}
            ),
            
            AgentType.RIF_PLANNER: AgentContextConfiguration(
                agent_type=AgentType.RIF_PLANNER,
                token_limit=8000,
                context_priorities={
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.CRITICAL,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.CRITICAL,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.HIGH,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.HIGH,
                    ContextType.RECENT_CHANGES: RelevanceLevel.HIGH,
                    ContextType.QUALITY_METRICS: RelevanceLevel.MEDIUM,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.MEDIUM,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.LOW
                },
                focus_areas=["strategic_planning", "workflow_design", "resource_allocation"],
                optimization_targets={"planning_depth": "strategic", "workflow_optimization": "comprehensive"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.9}
            ),
            
            AgentType.RIF_PR_MANAGER: AgentContextConfiguration(
                agent_type=AgentType.RIF_PR_MANAGER,
                token_limit=6000,
                context_priorities={
                    ContextType.RECENT_CHANGES: RelevanceLevel.CRITICAL,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.HIGH,
                    ContextType.QUALITY_METRICS: RelevanceLevel.HIGH,
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.MEDIUM,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.MEDIUM,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.LOW,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.LOW,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.LOW
                },
                focus_areas=["pull_request_management", "code_review", "integration"],
                optimization_targets={"pr_focus": "actionable", "review_efficiency": "high"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.8}
            ),
            
            AgentType.RIF_ERROR_ANALYST: AgentContextConfiguration(
                agent_type=AgentType.RIF_ERROR_ANALYST,
                token_limit=8000,
                context_priorities={
                    ContextType.RECENT_CHANGES: RelevanceLevel.CRITICAL,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.CRITICAL,
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.HIGH,
                    ContextType.QUALITY_METRICS: RelevanceLevel.HIGH,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.HIGH,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.MEDIUM,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.MEDIUM,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.LOW
                },
                focus_areas=["error_analysis", "debugging", "root_cause_analysis"],
                optimization_targets={"error_focus": "precise", "diagnostic_depth": "comprehensive"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.95}
            ),
            
            AgentType.RIF_SHADOW_AUDITOR: AgentContextConfiguration(
                agent_type=AgentType.RIF_SHADOW_AUDITOR,
                token_limit=10000,
                context_priorities={
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.CRITICAL,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.CRITICAL,
                    ContextType.QUALITY_METRICS: RelevanceLevel.CRITICAL,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.HIGH,
                    ContextType.RECENT_CHANGES: RelevanceLevel.HIGH,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.HIGH,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.MEDIUM,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.MEDIUM
                },
                focus_areas=["adversarial_review", "security_analysis", "compliance_audit"],
                optimization_targets={"audit_thoroughness": "maximal", "critical_analysis": "comprehensive"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.95}
            ),
            
            AgentType.RIF_PROJECTGEN: AgentContextConfiguration(
                agent_type=AgentType.RIF_PROJECTGEN,
                token_limit=12000,
                context_priorities={
                    ContextType.SYSTEM_OVERVIEW: RelevanceLevel.CRITICAL,
                    ContextType.ARCHITECTURAL_DESIGN: RelevanceLevel.CRITICAL,
                    ContextType.KNOWLEDGE_PATTERNS: RelevanceLevel.CRITICAL,
                    ContextType.DEPENDENCY_GRAPH: RelevanceLevel.HIGH,
                    ContextType.QUALITY_METRICS: RelevanceLevel.HIGH,
                    ContextType.RECENT_CHANGES: RelevanceLevel.MEDIUM,
                    ContextType.WORKFLOW_STATE: RelevanceLevel.MEDIUM,
                    ContextType.PERFORMANCE_DATA: RelevanceLevel.LOW
                },
                focus_areas=["project_generation", "template_creation", "best_practices"],
                optimization_targets={"generation_comprehensiveness": "maximal", "template_quality": "high"},
                performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.9}
            )
        }
    
    def get_agent_configuration(self, agent_type: AgentType) -> AgentContextConfiguration:
        """Get configuration for specific agent type"""
        return self.agent_configurations.get(agent_type, self._get_default_configuration())
    
    def _get_default_configuration(self) -> AgentContextConfiguration:
        """Get default configuration for unknown agent types"""
        return AgentContextConfiguration(
            agent_type=AgentType.RIF_ANALYST,
            token_limit=8000,
            context_priorities={ct: RelevanceLevel.MEDIUM for ct in ContextType},
            focus_areas=["general"],
            optimization_targets={"generic": "standard"},
            performance_requirements={"optimization_latency_ms": 50.0, "accuracy_threshold": 0.8}
        )

class SystemContextCollector:
    """Collects system context from various sources with freshness validation"""
    
    def __init__(self, repo_path: str = "/Users/cal/DEV/RIF"):
        self.repo_path = repo_path
        self.context_sources = self._initialize_context_sources()
        self.freshness_thresholds = {
            ContextType.RECENT_CHANGES: timedelta(hours=1),
            ContextType.WORKFLOW_STATE: timedelta(minutes=30),
            ContextType.PERFORMANCE_DATA: timedelta(hours=6),
            ContextType.SYSTEM_OVERVIEW: timedelta(hours=24),
            ContextType.ARCHITECTURAL_DESIGN: timedelta(days=7),
            ContextType.DEPENDENCY_GRAPH: timedelta(hours=12),
            ContextType.QUALITY_METRICS: timedelta(hours=6),
            ContextType.KNOWLEDGE_PATTERNS: timedelta(days=1)
        }
    
    def collect_system_context(self) -> List[SystemContextItem]:
        """Collect all available system context with freshness validation"""
        context_items = []
        
        for context_type in ContextType:
            try:
                items = self._collect_context_by_type(context_type)
                context_items.extend(items)
            except Exception as e:
                print(f"Error collecting {context_type.value} context: {e}")
        
        return context_items
    
    def _initialize_context_sources(self) -> Dict[ContextType, str]:
        """Initialize mapping of context types to source files/paths"""
        return {
            ContextType.SYSTEM_OVERVIEW: "systems/live-system-context-engine.py",
            ContextType.ARCHITECTURAL_DESIGN: "systems/context/live-system-context.json",
            ContextType.DEPENDENCY_GRAPH: "systems/dynamic-dependency-tracker.py",
            ContextType.WORKFLOW_STATE: "config/rif-workflow.yaml",
            ContextType.QUALITY_METRICS: "knowledge/metrics/",
            ContextType.RECENT_CHANGES: ".git/",
            ContextType.KNOWLEDGE_PATTERNS: "knowledge/patterns/",
            ContextType.PERFORMANCE_DATA: "knowledge/checkpoints/"
        }
    
    def _collect_context_by_type(self, context_type: ContextType) -> List[SystemContextItem]:
        """Collect context items of specific type"""
        context_items = []
        
        if context_type == ContextType.SYSTEM_OVERVIEW:
            items = self._collect_system_overview()
            context_items.extend(items)
        elif context_type == ContextType.RECENT_CHANGES:
            items = self._collect_recent_changes()
            context_items.extend(items)
        elif context_type == ContextType.DEPENDENCY_GRAPH:
            items = self._collect_dependency_graph()
            context_items.extend(items)
        elif context_type == ContextType.KNOWLEDGE_PATTERNS:
            items = self._collect_knowledge_patterns()
            context_items.extend(items)
        # ... other context type collections
        
        return context_items
    
    def _collect_system_overview(self) -> List[SystemContextItem]:
        """Collect system overview context"""
        overview_file = Path(self.repo_path) / "systems" / "context" / "live-system-context.json"
        
        if overview_file.exists():
            try:
                with open(overview_file, 'r') as f:
                    overview_data = json.load(f)
                
                freshness_score = self._calculate_freshness_score(
                    overview_file.stat().st_mtime,
                    ContextType.SYSTEM_OVERVIEW
                )
                
                return [SystemContextItem(
                    context_type=ContextType.SYSTEM_OVERVIEW,
                    content=overview_data,
                    relevance_score=1.0,  # System overview is always highly relevant
                    token_estimate=len(json.dumps(overview_data)) // 4,  # Rough token estimate
                    freshness_score=freshness_score,
                    accuracy_score=0.95,  # High accuracy for live system context
                    source_component="live-system-context-engine",
                    last_updated=datetime.fromtimestamp(overview_file.stat().st_mtime)
                )]
            except Exception as e:
                print(f"Error reading system overview: {e}")
        
        return []
    
    def _collect_recent_changes(self) -> List[SystemContextItem]:
        """Collect recent changes context"""
        try:
            import subprocess
            result = subprocess.run(
                ['git', 'log', '--oneline', '--since=1 hour ago'],
                cwd=self.repo_path,
                capture_output=True,
                text=True,
                timeout=10
            )
            
            if result.stdout:
                changes_data = {
                    'recent_commits': result.stdout.strip().split('\n'),
                    'timestamp': datetime.now().isoformat()
                }
                
                return [SystemContextItem(
                    context_type=ContextType.RECENT_CHANGES,
                    content=changes_data,
                    relevance_score=0.9,
                    token_estimate=len(result.stdout) // 4,
                    freshness_score=1.0,  # Very fresh
                    accuracy_score=1.0,  # Git data is accurate
                    source_component="git-log",
                    last_updated=datetime.now()
                )]
        except Exception as e:
            print(f"Error collecting recent changes: {e}")
        
        return []
    
    def _collect_dependency_graph(self) -> List[SystemContextItem]:
        """Collect dependency graph context"""
        # Implementation would integrate with existing dependency tracker
        return []
    
    def _collect_knowledge_patterns(self) -> List[SystemContextItem]:
        """Collect knowledge patterns context"""
        patterns_dir = Path(self.repo_path) / "knowledge" / "patterns"
        patterns_items = []
        
        if patterns_dir.exists():
            for pattern_file in patterns_dir.glob("*.json"):
                try:
                    with open(pattern_file, 'r') as f:
                        pattern_data = json.load(f)
                    
                    freshness_score = self._calculate_freshness_score(
                        pattern_file.stat().st_mtime,
                        ContextType.KNOWLEDGE_PATTERNS
                    )
                    
                    patterns_items.append(SystemContextItem(
                        context_type=ContextType.KNOWLEDGE_PATTERNS,
                        content=pattern_data,
                        relevance_score=0.8,
                        token_estimate=len(json.dumps(pattern_data)) // 4,
                        freshness_score=freshness_score,
                        accuracy_score=0.9,
                        source_component=pattern_file.name,
                        last_updated=datetime.fromtimestamp(pattern_file.stat().st_mtime)
                    ))
                except Exception as e:
                    print(f"Error reading pattern {pattern_file}: {e}")
        
        return patterns_items
    
    def _calculate_freshness_score(self, file_mtime: float, context_type: ContextType) -> float:
        """Calculate freshness score based on file modification time and context type"""
        last_modified = datetime.fromtimestamp(file_mtime)
        age = datetime.now() - last_modified
        threshold = self.freshness_thresholds.get(context_type, timedelta(hours=24))
        
        if age <= threshold:
            return 1.0
        elif age <= threshold * 2:
            return 0.8
        elif age <= threshold * 5:
            return 0.5
        else:
            return 0.2

class InformationOverloadPreventer:
    """Prevents information overload using intelligent pruning and filtering"""
    
    def __init__(self, configurator: AgentContextConfigurator):
        self.configurator = configurator
        self.multi_factor_weights = {
            'text': 0.40,
            'semantic': 0.30,
            'structural': 0.20,
            'temporal': 0.10
        }
    
    def prevent_overload(self, agent_type: AgentType, 
                        context_items: List[SystemContextItem]) -> List[SystemContextItem]:
        """Apply intelligent pruning to prevent information overload"""
        start_time = time.time()
        
        config = self.configurator.get_agent_configuration(agent_type)
        
        # Step 1: Filter by relevance level
        filtered_items = self._filter_by_relevance(context_items, config)
        
        # Step 2: Apply multi-factor scoring
        scored_items = self._apply_multi_factor_scoring(filtered_items, config)
        
        # Step 3: Optimize for token limit
        optimized_items = self._optimize_for_token_limit(scored_items, config.token_limit)
        
        # Step 4: Ensure critical context is preserved
        final_items = self._preserve_critical_context(optimized_items, context_items, config)
        
        optimization_duration = (time.time() - start_time) * 1000  # Convert to ms
        
        # Validate performance requirement
        if optimization_duration > config.performance_requirements.get("optimization_latency_ms", 50.0):
            print(f"Warning: Optimization took {optimization_duration:.1f}ms, exceeding {config.performance_requirements.get('optimization_latency_ms', 50.0)}ms target")
        
        return final_items
    
    def _filter_by_relevance(self, context_items: List[SystemContextItem], 
                           config: AgentContextConfiguration) -> List[SystemContextItem]:
        """Filter context items by agent-specific relevance levels"""
        filtered_items = []
        
        for item in context_items:
            priority = config.context_priorities.get(item.context_type, RelevanceLevel.MEDIUM)
            
            # Only include items that meet the relevance threshold
            if priority in [RelevanceLevel.CRITICAL, RelevanceLevel.HIGH]:
                filtered_items.append(item)
            elif priority == RelevanceLevel.MEDIUM and item.relevance_score >= 0.6:
                filtered_items.append(item)
            elif priority == RelevanceLevel.LOW and item.relevance_score >= 0.8:
                filtered_items.append(item)
            # IRRELEVANT items are always excluded
        
        return filtered_items
    
    def _apply_multi_factor_scoring(self, context_items: List[SystemContextItem], 
                                  config: AgentContextConfiguration) -> List[SystemContextItem]:
        """Apply multi-factor relevance scoring (40% text, 30% semantic, 20% structural, 10% temporal)"""
        for item in context_items:
            # Multi-factor score calculation
            text_score = item.relevance_score
            semantic_score = self._calculate_semantic_score(item, config)
            structural_score = self._calculate_structural_score(item, config)
            temporal_score = item.freshness_score
            
            # Combined score using research-proven weights
            combined_score = (
                self.multi_factor_weights['text'] * text_score +
                self.multi_factor_weights['semantic'] * semantic_score +
                self.multi_factor_weights['structural'] * structural_score +
                self.multi_factor_weights['temporal'] * temporal_score
            )
            
            # Update relevance score with multi-factor result
            item.relevance_score = min(1.0, combined_score)
        
        # Sort by relevance score
        context_items.sort(key=lambda x: x.relevance_score, reverse=True)
        
        return context_items
    
    def _calculate_semantic_score(self, item: SystemContextItem, 
                                config: AgentContextConfiguration) -> float:
        """Calculate semantic relevance score based on agent focus areas"""
        content_text = json.dumps(item.content).lower()
        focus_matches = 0
        
        for focus_area in config.focus_areas:
            if focus_area.lower().replace('_', ' ') in content_text:
                focus_matches += 1
        
        return min(1.0, focus_matches / max(len(config.focus_areas), 1))
    
    def _calculate_structural_score(self, item: SystemContextItem, 
                                  config: AgentContextConfiguration) -> float:
        """Calculate structural importance score"""
        # Critical context types get higher structural scores
        if config.context_priorities.get(item.context_type) == RelevanceLevel.CRITICAL:
            return 1.0
        elif config.context_priorities.get(item.context_type) == RelevanceLevel.HIGH:
            return 0.8
        elif config.context_priorities.get(item.context_type) == RelevanceLevel.MEDIUM:
            return 0.6
        else:
            return 0.4
    
    def _optimize_for_token_limit(self, context_items: List[SystemContextItem], 
                                token_limit: int) -> List[SystemContextItem]:
        """Optimize context selection to fit within token limit"""
        optimized_items = []
        total_tokens = 0
        
        for item in context_items:
            if total_tokens + item.token_estimate <= token_limit:
                optimized_items.append(item)
                total_tokens += item.token_estimate
            else:
                # Check if we can include a smaller version
                if total_tokens < token_limit * 0.9:  # Leave 10% buffer
                    # Could implement content summarization here
                    pass
                break
        
        return optimized_items
    
    def _preserve_critical_context(self, optimized_items: List[SystemContextItem],
                                 all_items: List[SystemContextItem],
                                 config: AgentContextConfiguration) -> List[SystemContextItem]:
        """Ensure critical context is always included"""
        critical_types = [
            ct for ct, priority in config.context_priorities.items() 
            if priority == RelevanceLevel.CRITICAL
        ]
        
        # Ensure at least one item of each critical type is included
        included_types = {item.context_type for item in optimized_items}
        
        for critical_type in critical_types:
            if critical_type not in included_types:
                # Find the best item of this critical type
                critical_items = [item for item in all_items if item.context_type == critical_type]
                if critical_items:
                    best_critical_item = max(critical_items, key=lambda x: x.relevance_score)
                    # Add it, potentially removing a less important item to make room
                    optimized_items.append(best_critical_item)
        
        return optimized_items

class EnhancedAgentContextDelivery:
    """Main enhanced agent context delivery system implementing research findings"""
    
    def __init__(self, repo_path: str = "/Users/cal/DEV/RIF"):
        self.repo_path = repo_path
        self.configurator = AgentContextConfigurator()
        self.context_collector = SystemContextCollector(repo_path)
        self.overload_preventer = InformationOverloadPreventer(self.configurator)
        self.delivery_history = []
    
    def deliver_optimized_context(self, agent_type: AgentType, 
                                current_task: Optional[str] = None) -> OptimizedContextDelivery:
        """Deliver optimized context to specific agent type"""
        start_time = time.time()
        
        # Step 1: Collect all available system context
        all_context = self.context_collector.collect_system_context()
        
        # Step 2: Apply information overload prevention
        optimized_context = self.overload_preventer.prevent_overload(agent_type, all_context)
        
        # Step 3: Calculate delivery metrics
        optimization_duration_ms = (time.time() - start_time) * 1000
        total_tokens = sum(item.token_estimate for item in optimized_context)
        
        # Step 4: Calculate quality scores
        context_freshness_score = sum(item.freshness_score for item in optimized_context) / max(len(optimized_context), 1)
        relevance_filtering_applied = len(optimized_context) < len(all_context)
        
        config = self.configurator.get_agent_configuration(agent_type)
        information_overload_prevented = total_tokens <= config.token_limit
        
        # Step 5: Create delivery result
        delivery = OptimizedContextDelivery(
            agent_type=agent_type,
            context_items=optimized_context,
            total_tokens=total_tokens,
            optimization_duration_ms=optimization_duration_ms,
            relevance_filtering_applied=relevance_filtering_applied,
            information_overload_prevented=information_overload_prevented,
            context_freshness_score=context_freshness_score,
            delivery_timestamp=datetime.now()
        )
        
        self.delivery_history.append(delivery)
        
        # Validate performance requirements
        if optimization_duration_ms > config.performance_requirements.get("optimization_latency_ms", 50.0):
            print(f"âš ï¸  Performance requirement not met: {optimization_duration_ms:.1f}ms > {config.performance_requirements.get('optimization_latency_ms', 50.0)}ms")
        
        return delivery
    
    def get_performance_metrics(self) -> Dict[str, Any]:
        """Get performance metrics for context delivery system"""
        if not self.delivery_history:
            return {}
        
        recent_deliveries = self.delivery_history[-10:]
        
        return {
            'average_optimization_duration_ms': sum(d.optimization_duration_ms for d in recent_deliveries) / len(recent_deliveries),
            'average_context_freshness_score': sum(d.context_freshness_score for d in recent_deliveries) / len(recent_deliveries),
            'overload_prevention_rate': sum(1 for d in recent_deliveries if d.information_overload_prevented) / len(recent_deliveries),
            'filtering_effectiveness_rate': sum(1 for d in recent_deliveries if d.relevance_filtering_applied) / len(recent_deliveries),
            'sub_50ms_achievement_rate': sum(1 for d in recent_deliveries if d.optimization_duration_ms <= 50.0) / len(recent_deliveries),
            'total_deliveries': len(self.delivery_history)
        }

def main():
    """Main entry point for testing enhanced agent context delivery"""
    delivery_system = EnhancedAgentContextDelivery()
    
    print("RIF Agent Context Delivery Enhancement")
    print("=====================================")
    print()
    
    # Test context delivery for different agent types
    test_agents = [
        AgentType.RIF_ANALYST,
        AgentType.RIF_ARCHITECT,
        AgentType.RIF_IMPLEMENTER,
        AgentType.RIF_VALIDATOR
    ]
    
    for agent_type in test_agents:
        print(f"Testing context delivery for {agent_type.value}...")
        delivery = delivery_system.deliver_optimized_context(agent_type)
        
        print(f"  âœ… Optimized in {delivery.optimization_duration_ms:.1f}ms")
        print(f"  ðŸ“Š Context items: {len(delivery.context_items)}")
        print(f"  ðŸŽ¯ Total tokens: {delivery.total_tokens}")
        print(f"  ðŸ” Relevance filtering: {'âœ…' if delivery.relevance_filtering_applied else 'âŒ'}")
        print(f"  ðŸ›¡ï¸  Overload prevention: {'âœ…' if delivery.information_overload_prevented else 'âŒ'}")
        print(f"  ðŸ“ˆ Freshness score: {delivery.context_freshness_score:.2f}")
        print()
    
    # Show overall performance metrics
    metrics = delivery_system.get_performance_metrics()
    if metrics:
        print("ðŸ“ˆ Performance Metrics:")
        print(f"  â€¢ Average optimization duration: {metrics['average_optimization_duration_ms']:.1f}ms")
        print(f"  â€¢ Sub-50ms achievement rate: {metrics['sub_50ms_achievement_rate']:.1%}")
        print(f"  â€¢ Overload prevention rate: {metrics['overload_prevention_rate']:.1%}")
        print(f"  â€¢ Context freshness score: {metrics['average_context_freshness_score']:.2f}")

if __name__ == "__main__":
    main()